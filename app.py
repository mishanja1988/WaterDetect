–¥–µ—Ä–∂–∏ —Ü–µ–ª—å–Ω—ã–π, —É—Å—Ç–æ–π—á–∏–≤—ã–π **–æ–¥–∏–Ω —Ñ–∞–π–ª** `app.py`. –û–Ω:

* –±–µ—Ä—ë—Ç —à–∞–±–ª–æ–Ω –∏–∑ `data/templates/–°–æ—Å–Ω–æ–≤—Å–∫–æ–µ_clean.xlsx`;
* —Å–æ–∑–¥–∞—ë—Ç `Well_calc = H + " " + I` –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –µ–≥–æ –∫–∞–∫ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä —Å–∫–≤–∞–∂–∏–Ω—ã;
* –¥–æ–±–∞–≤–ª—è–µ—Ç —Å—Ç–æ–ª–±—Ü—ã:

  * `–î–æ–±—ã—á–∞ –Ω–µ—Ñ—Ç–∏ –º3/–º–µ—Å = X * (100 - AB)/100`
  * `–î–æ–±—ã—á–∞ –≤–æ–¥—ã –º3/–º–µ—Å = X * AB/100`
  * `–í–ù–§ = BT/BS`
  * `–ù–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã = –ï–°–õ–ò(BR[i]==BR[i-1]; AJ[i] + cum[i-1]; AJ[i])` (–≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–π `Well_calc`)
  * `–í–ù–§` ‚Äî –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –ø–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–º—É –≤—Ä–µ–º–µ–Ω–∏
* —Å—á–∏—Ç–∞–µ—Ç MG –∏ Chan (Chan-–≥—Ä–∞—Ñ–∏–∫ log‚Äìlog –Ω–∞ –æ–±—â–∏—Ö –æ—Å—è—Ö);
* –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏ –≤ —Å—Ç—Ä–∏–º–ª–∏—Ç–µ;
* –≤—ã–≥—Ä—É–∂–∞–µ—Ç **–æ–¥–∏–Ω Excel** `Autodiagnostics_results.xlsx` —Å –ª–∏—Å—Ç–∞–º–∏ `Summary`, `MG`, `Chan`, –≥–¥–µ –ø–æ –∫–∞–∂–¥–æ–π —Å–∫–≤–∞–∂–∏–Ω–µ —Ç–∞–±–ª–∏—Ü–∞ –∏ **–∫–∞—Ä—Ç–∏–Ω–∫–∞ –≥—Ä–∞—Ñ–∏–∫–∞ —Ä—è–¥–æ–º**.

–ó–∞–ø—É—Å–∫:

```bash
pip install streamlit pandas numpy matplotlib openpyxl xlsxwriter
streamlit run app.py
```

```python
# app.py ‚Äî –ê–≤—Ç–æ–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å–∫–≤–∞–∂–∏–Ω (–≤—Å—ë –≤ –æ–¥–Ω–æ–º —Ñ–∞–π–ª–µ)
# ----------------------------------------------------
from __future__ import annotations

import os
import re
import unicodedata
from dataclasses import dataclass
from io import BytesIO
from typing import Dict, List, Optional

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import streamlit as st

# =========================
# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
# =========================
EPS = 1e-9
TEMPLATE_PATH = "data/templates/–°–æ—Å–Ω–æ–≤—Å–∫–æ–µ_clean.xlsx"

st.set_page_config(
    layout="wide",
    initial_sidebar_state="auto",
    page_title="–ê–≤—Ç–æ–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å–∫–≤–∞–∂–∏–Ω",
    page_icon="üõ¢Ô∏è",
)

st.write("### –ü–æ—Å–∫–≤–∞–∂–∏–Ω–Ω—ã–π –∞–≤—Ç–æ–¥–∏–∞–≥–Ω–æ–∑ –Ω–µ—Ñ—Ç—è–Ω—ã—Ö —Å–∫–≤–∞–∂–∏–Ω –ø–æ –º–µ—Ö–∞–Ω–∏–∑–º—É –æ–±–≤–æ–¥–Ω–µ–Ω–∏—è")
st.markdown(
    """
**–°—É—Ç—å —Ä–∞–±–æ—Ç—ã:** –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ —Ä–∞—Å—á—ë—Ç–Ω–æ-–∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–≤—Ç–æ–¥–∏–∞–≥–Ω–æ–∑–∞ –º–µ—Ö–∞–Ω–∏–∑–º–∞ –æ–±–≤–æ–¥–Ω–µ–Ω–∏—è –ø–æ –º–µ—Ç–æ–¥–∏–∫–∞–º –ß–µ–Ω–∞ (Chan) –∏ –ú–µ—Ä–∫—É–ª–æ–≤–æ–π‚Äì–ì–∏–Ω–∑–±—É—Ä–≥–∞ (MG) –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.

**–ß—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–¥–µ–ª–∞—Ç—å:**  
1) –°–∫–∞—á–∞—Ç—å —à–∞–±–ª–æ–Ω –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, 2) –∑–∞–ø–æ–ª–Ω–∏—Ç—å, 3) –∑–∞–≥—Ä—É–∑–∏—Ç—å,  
4) –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π –∏ –≤–∏–∑—É–∞–ª—å–Ω—ã–π –¥–∏–∞–≥–Ω–æ–∑ –ø–æ –∫–∞–∂–¥–æ–π —Å–∫–≤–∞–∂–∏–Ω–µ,  
5) —Å–∫–∞—á–∞—Ç—å **–µ–¥–∏–Ω—ã–π Excel** —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏ –∏ –≥—Ä–∞—Ñ–∏–∫–∞–º–∏.
"""
)

# =========================
# –£—Ç–∏–ª–∏—Ç—ã
# =========================
def excel_letter_to_index(letter: str) -> int:
    """A->0, B->1, ..., Z->25, AA->26, AB->27, ..."""
    letter = letter.strip().upper()
    acc = 0
    for ch in letter:
        if not ("A" <= ch <= "Z"):
            raise ValueError(f"–ù–µ–≤–µ—Ä–Ω–∞—è –±—É–∫–≤–∞ —Å—Ç–æ–ª–±—Ü–∞ Excel: {letter}")
        acc = acc * 26 + (ord(ch) - ord("A") + 1)
    return acc - 1

def col_by_letter(df: pd.DataFrame, letter: str) -> Optional[str]:
    """–í–µ—Ä–Ω—É—Ç—å –∏–º—è —Å—Ç–æ–ª–±—Ü–∞ –ø–æ –±—É–∫–≤–µ Excel —Å —É—á—ë—Ç–æ–º —Ç–µ–∫—É—â–µ–≥–æ –ø–æ—Ä—è–¥–∫–∞ –∫–æ–ª–æ–Ω–æ–∫."""
    idx = excel_letter_to_index(letter)
    return df.columns[idx] if 0 <= idx < len(df.columns) else None

def series_by_letter(df: pd.DataFrame, letter: str) -> Optional[pd.Series]:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ –≤–µ—Ä–Ω—É—Ç—å —Å–µ—Ä–∏—é –ø–æ –±—É–∫–≤–µ (–∏–ª–∏ None)."""
    col = col_by_letter(df, letter)
    if col is None or col not in df.columns:
        return None
    return df[col]

def normalize_header(s: str) -> str:
    if not isinstance(s, str):
        return s
    s = unicodedata.normalize("NFKC", s).replace("\u00A0", " ").replace("\xa0", " ")
    s = re.sub(r"\s+", " ", s.strip())
    return s

def save_df_to_excel(df: pd.DataFrame, ind: bool = False) -> BytesIO:
    out = BytesIO()
    df.to_excel(out, index=ind, engine="openpyxl")
    out.seek(0)
    return out

def to_num_or_nan(ser: Optional[pd.Series], df: pd.DataFrame, fill: Optional[float] = None) -> pd.Series:
    """
    –í–µ—Ä–Ω—É—Ç—å —á–∏—Å–ª–æ–≤—É—é —Å–µ—Ä–∏—é –¥–ª–∏–Ω–æ–π df. –ï—Å–ª–∏ ser=None ‚Äî NaN (–∏–ª–∏ fill, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω).
    """
    if isinstance(ser, pd.Series):
        out = pd.to_numeric(ser, errors="coerce")
    else:
        out = pd.Series(np.nan, index=df.index, dtype=float)
    if fill is not None:
        out = out.fillna(fill)
    return out

def read_template_df() -> pd.DataFrame:
    try:
        if os.path.exists(TEMPLATE_PATH):
            return pd.read_excel(TEMPLATE_PATH)
    except Exception:
        pass
    return pd.DataFrame()

def upload_examples() -> None:
    tpl = read_template_df()
    st.write("**–°–∫–∞—á–∞—Ç—å —à–∞–±–ª–æ–Ω –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:**")
    c1, c2, *_ = st.columns(9)
    c1.download_button(
        "–°–∫–∞—á–∞—Ç—å —à–∞–±–ª–æ–Ω (CSV)",
        data=tpl.to_csv(index=False),
        file_name="template_from_attachment.csv",
        mime="text/csv",
    )
    c2.download_button(
        "–°–∫–∞—á–∞—Ç—å —à–∞–±–ª–æ–Ω (XLSX)",
        data=save_df_to_excel(tpl),
        file_name="template_from_attachment.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

# =========================
# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥ MG/Chan
# =========================
def enforce_monotonic_per_well(dfin: pd.DataFrame) -> pd.DataFrame:
    out = []
    for w, g in dfin.groupby("well", sort=False):
        t = g["t_num"].to_numpy(dtype=float)
        for i in range(1, t.size):
            if t[i] <= t[i - 1]:
                t[i] = t[i - 1] + EPS
        g2 = g.copy()
        g2["t_num"] = t
        out.append(g2)
    return pd.concat(out, axis=0).reset_index(drop=True)

def compute_cum_work_time(group: pd.DataFrame,
                          col_BR: Optional[str],
                          col_AJ: Optional[str]) -> pd.Series:
    """
    –ù–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã –≤–Ω—É—Ç—Ä–∏ –≥—Ä—É–ø–ø—ã Well_calc:
    –µ—Å–ª–∏ BR[i]==BR[i-1] ‚Üí AJ[i] + cum[i-1], –∏–Ω–∞—á–µ AJ[i]
    """
    if col_BR and col_BR in group.columns:
        br = group[col_BR].astype(str).fillna("")
    else:
        br = pd.Series([""] * len(group), index=group.index)

    if col_AJ and col_AJ in group.columns:
        aj = pd.to_numeric(group[col_AJ], errors="coerce").fillna(0.0).to_numpy()
    else:
        aj = np.zeros(len(group), dtype=float)

    out = np.zeros(len(group), dtype=float)
    for i in range(len(group)):
        out[i] = aj[i] if i == 0 or br.iloc[i] != br.iloc[i - 1] else aj[i] + out[i - 1]
    return pd.Series(out, index=group.index, name="–ù–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã")

def data_preparation(init_data: pd.DataFrame) -> pd.DataFrame:
    dfn = init_data.copy()
    dfn.columns = [normalize_header(c) for c in dfn.columns]

    # –ë–µ—Ä—ë–º —Å–µ—Ä–∏–∏ –ø–æ –±—É–∫–≤–∞–º —Å—Ç–æ–ª–±—Ü–æ–≤ (—É—Å—Ç–æ–π—á–∏–≤–æ –∫ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—é)
    sH  = series_by_letter(dfn, "H")    # –°–∫–≤–∞–∂–∏–Ω–∞
    sI  = series_by_letter(dfn, "I")    # –û–±—ä–µ–∫—Ç
    sX  = series_by_letter(dfn, "X")    # –ñ–∏–¥–∫–æ—Å—Ç—å, –º3/–º–µ—Å
    sAB = series_by_letter(dfn, "AB")   # –û–±–≤–æ–¥–Ω—ë–Ω–Ω–æ—Å—Ç—å, %
    sBT = series_by_letter(dfn, "BT")   # –í–ù–§ —á–∏—Å–ª–∏—Ç–µ–ª—å
    sBS = series_by_letter(dfn, "BS")   # –í–ù–§ –∑–Ω–∞–º–µ–Ω–∞—Ç–µ–ª—å
    sBR = series_by_letter(dfn, "BR")   # –ü–µ—Ä–∏–æ–¥ (–∫–ª—é—á)
    sAJ = series_by_letter(dfn, "AJ")   # –î–Ω–∏ —Ä–∞–±–æ—Ç—ã

    # Well_calc = H + " " + I
    if sH is not None and sI is not None:
        dfn["Well_calc"] = sH.astype(str).str.strip().fillna("") + " " + sI.astype(str).str.strip().fillna("")
    elif sH is not None:
        dfn["Well_calc"] = sH.astype(str).str.strip().fillna("")
    elif sI is not None:
        dfn["Well_calc"] = sI.astype(str).str.strip().fillna("")
    else:
        dfn["Well_calc"] = ""
    dfn["well"] = dfn["Well_calc"]

    # –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
    X_vals  = to_num_or_nan(sX,  dfn)
    AB_vals = to_num_or_nan(sAB, dfn)
    dfn["–î–æ–±—ã—á–∞ –Ω–µ—Ñ—Ç–∏ –º3/–º–µ—Å"] = X_vals * (100.0 - AB_vals) / 100.0
    dfn["–î–æ–±—ã—á–∞ –≤–æ–¥—ã –º3/–º–µ—Å"]  = X_vals * AB_vals / 100.0

    BT_vals = to_num_or_nan(sBT, dfn)
    BS_vals = to_num_or_nan(sBS, dfn)
    with np.errstate(divide="ignore", invalid="ignore"):
        dfn["–í–ù–§"] = BT_vals / BS_vals

    # –ù–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–π Well_calc
    cBR = col_by_letter(dfn, "BR")
    cAJ = col_by_letter(dfn, "AJ")
    dfn["–ù–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã"] = 0.0
    for w, g in dfn.groupby("Well_calc", sort=False):
        dfn.loc[g.index, "–ù–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã"] = compute_cum_work_time(g, cBR, cAJ)

    # –í–ù–§' ‚Äî –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è –ø–æ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–º—É –≤—Ä–µ–º–µ–Ω–∏ (–ø–æ—à—Ç—É—á–Ω–æ –ø–æ Well_calc)
    try:
        t_all = pd.to_numeric(dfn["–ù–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã"], errors="coerce").to_numpy()
        y_all = pd.to_numeric(dfn["–í–ù–§"], errors="coerce").to_numpy()
        grad = np.full(len(dfn), np.nan)
        for w, g in dfn.groupby("Well_calc", sort=False):
            idx = g.index.to_numpy()
            with np.errstate(invalid="ignore"):
                grad[idx] = np.gradient(y_all[idx], t_all[idx])
        dfn["–í–ù–§'"] = grad
    except Exception:
        dfn["–í–ù–§'"] = np.nan

    # –û–±—ä—ë–º—ã –ø–µ—Ä–∏–æ–¥–∞ –∏ —Å—É—Ç–æ—á–Ω—ã–µ –¥–µ–±–∏—Ç—ã
    dfn["qo_period"] = pd.to_numeric(dfn["–î–æ–±—ã—á–∞ –Ω–µ—Ñ—Ç–∏ –º3/–º–µ—Å"], errors="coerce").fillna(0.0)
    dfn["qw_period"] = pd.to_numeric(dfn["–î–æ–±—ã—á–∞ –≤–æ–¥—ã –º3/–º–µ—Å"],  errors="coerce").fillna(0.0)
    dfn["qL_period"] = dfn["qo_period"] + dfn["qw_period"]

    prod_days = to_num_or_nan(sAJ, dfn, fill=0.0)
    dfn["prod_days"] = prod_days
    dfn["qo"] = np.where(dfn["prod_days"] > 0, dfn["qo_period"] / dfn["prod_days"], np.nan)
    dfn["qw"] = np.where(dfn["prod_days"] > 0, dfn["qw_period"] / dfn["prod_days"], np.nan)
    dfn["qL"] = np.where(dfn["prod_days"] > 0, dfn["qL_period"] / dfn["prod_days"], np.nan)

    # –í—Ä–µ–º—è –¥–ª—è –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤
    dfn["t_num"] = pd.to_numeric(dfn["–ù–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã"], errors="coerce").fillna(0.0)

    # –ü–æ—Ä—è–¥–æ–∫ –∏ –º–æ–Ω–æ—Ç–æ–Ω–Ω–æ—Å—Ç—å –ø–æ —Å–∫–≤–∞–∂–∏–Ω–µ
    dfn = dfn.dropna(subset=["well", "t_num"]).sort_values(["well", "t_num"]).reset_index(drop=True)
    dfn = enforce_monotonic_per_well(dfn)
    return dfn

# =========================
# MG
# =========================
@dataclass
class MGFlags:
    y_early_mean: Optional[float] = None
    slope_first_third: Optional[float] = None
    waviness_std: Optional[float] = None
    possible_behind_casing: bool = False
    possible_channeling: bool = False
    possible_mixed_causes: bool = False

def compute_mg_full(df_in: pd.DataFrame, watercut_thr: float = 0.02, min_points: int = 8) -> pd.DataFrame:
    d = df_in.copy()
    with np.errstate(divide="ignore", invalid="ignore"):
        d["fw"] = np.where(d["qL_period"] > 0, d["qw_period"] / d["qL_period"], np.nan)

    frames = []
    for w, g in d.groupby("well", sort=False):
        g = g.sort_values("t_num").copy()
        idx = g.index[g["fw"] > watercut_thr]
        if len(idx) == 0 or len(g) < min_points:
            continue
        g2 = g.loc[idx[0]:].copy()

        g2["Qo_cum"] = g2["qo_period"].cumsum()
        g2["Qw_cum"] = g2["qw_period"].cumsum()
        g2["Qt_cum"] = g2["Qo_cum"] + g2["Qw_cum"]

        Qt_T = float(g2["Qt_cum"].iloc[-1])
        if Qt_T <= 0 or len(g2) < min_points:
            continue

        X = (g2["Qt_cum"] / Qt_T).to_numpy()
        for i in range(1, X.size):
            if X[i] <= X[i - 1]:
                X[i] = X[i - 1] + EPS
        g2["MG_X"] = X
        with np.errstate(invalid="ignore", divide="ignore"):
            g2["MG_Y"] = np.where(g2["Qt_cum"] > 0, g2["Qo_cum"] / g2["Qt_cum"], np.nan)

        flags = MGFlags()
        early_mask = g2["MG_X"] <= 0.2
        if early_mask.sum() >= 3:
            flags.y_early_mean = float(np.nanmean(g2.loc[early_mask, "MG_Y"]))
            flags.possible_behind_casing = (flags.y_early_mean is not None) and (flags.y_early_mean >= 0.99)

        first_third = g2[g2["MG_X"] <= 0.33]
        if len(first_third) >= 3:
            x = first_third["MG_X"].to_numpy()
            y = first_third["MG_Y"].to_numpy()
            A = np.vstack([x, np.ones_like(x)]).T
            try:
                k, _ = np.linalg.lstsq(A, y, rcond=None)[0]
                flags.slope_first_third = float(k)
                flags.possible_channeling = (k < -0.8)
            except Exception:
                pass

        if len(g2) >= 5:
            with np.errstate(invalid="ignore"):
                dy = np.gradient(g2["MG_Y"].to_numpy(), g2["MG_X"].to_numpy())
            flags.waviness_std = float(np.nanstd(dy))
            flags.possible_mixed_causes = flags.waviness_std > 1.0

        for key, val in {
            "MG_diag_y_early_mean": flags.y_early_mean,
            "MG_diag_slope_first_third": flags.slope_first_third,
            "MG_diag_waviness_std": flags.waviness_std,
            "MG_flag_behind_casing": flags.possible_behind_casing,
            "MG_flag_channeling": flags.possible_channeling,
            "MG_flag_mixed": flags.possible_mixed_causes,
        }.items():
            g2[key] = val

        frames.append(g2.assign(well=w))

    return pd.concat(frames, axis=0).reset_index(drop=True) if frames else pd.DataFrame()

# =========================
# Chan
# =========================
@dataclass
class ChanFlags:
    slope_logWOR_logt: Optional[float] = None
    mean_derivative: Optional[float] = None
    std_derivative: Optional[float] = None
    possible_coning: bool = False
    possible_near_wellbore: bool = False
    possible_multilayer_channeling: bool = False

def compute_chan_full(df_in: pd.DataFrame, min_points: int = 10) -> pd.DataFrame:
    frames = []
    for w, g in df_in.groupby("well", sort=False):
        g = g.sort_values("t_num").copy()
        with np.errstate(divide="ignore", invalid="ignore"):
            g["WOR"] = g["qw"] / g["qo"]
        g = g.replace([np.inf, -np.inf], np.nan)
        g = g[(g["qo"] > 0) & (g["WOR"] > 0)].dropna(subset=["WOR"])
        if len(g) < min_points:
            continue

        with np.errstate(invalid="ignore"):
            g["t_pos"] = g["t_num"] - g["t_num"].min() + EPS
            g["dWOR_dt"] = np.gradient(g["WOR"].to_numpy(), g["t_pos"].to_numpy())

        mask = (g["WOR"] > 0) & (g["t_pos"] > 0)
        x = np.log(g.loc[mask, "t_pos"].to_numpy())
        y = np.log(g.loc[mask, "WOR"].to_numpy())
        if len(x) >= 3:
            A = np.vstack([x, np.ones_like(x)]).T
            try:
                a, _ = np.linalg.lstsq(A, y, rcond=None)[0]
            except Exception:
                a = np.nan
        else:
            a = np.nan

        mean_deriv = float(np.nanmean(g["dWOR_dt"])) if len(g) else np.nan
        std_deriv  = float(np.nanstd(g["dWOR_dt"])) if len(g) else np.nan

        g["well"] = w
        g["chan_slope_logWOR_logt"] = float(a) if a == a else np.nan
        g["chan_mean_dWOR_dt"] = mean_deriv
        g["chan_std_dWOR_dt"] = std_deriv
        g["chan_flag_coning"] = (a > 0.5 and mean_deriv > 0) if a == a else False
        g["chan_flag_near_wellbore"] = (a > 1.0 and mean_deriv > 0) if a == a else False
        g["chan_flag_multilayer_channeling"] = (a > 0 and std_deriv > 0.1) if a == a else False

        # –î–ª—è –≥—Ä–∞—Ñ–∏–∫–∞ log‚Äìlog –ø–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–Ω—É—é
        g["dWOR_dt_pos"] = np.where(g["dWOR_dt"] > 0, g["dWOR_dt"], np.nan)

        frames.append(g)

    return pd.concat(frames, axis=0).reset_index(drop=True) if frames else pd.DataFrame()

# =========================
# –¢–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∏–∞–≥–Ω–æ–∑—ã
# =========================
def diagnose_mg_group(g: pd.DataFrame) -> Dict[str, str]:
    y_early = g["MG_diag_y_early_mean"].dropna().iloc[-1] if "MG_diag_y_early_mean" in g and g["MG_diag_y_early_mean"].notna().any() else np.nan
    slope   = g["MG_diag_slope_first_third"].dropna().iloc[-1] if "MG_diag_slope_first_third" in g and g["MG_diag_slope_first_third"].notna().any() else np.nan
    wav     = g["MG_diag_waviness_std"].dropna().iloc[-1] if "MG_diag_waviness_std" in g and g["MG_diag_waviness_std"].notna().any() else np.nan
    f_bc = bool(g["MG_flag_behind_casing"].dropna().iloc[-1]) if "MG_flag_behind_casing" in g and g["MG_flag_behind_casing"].notna().any() else False
    f_ch = bool(g["MG_flag_channeling"].dropna().iloc[-1]) if "MG_flag_channeling" in g and g["MG_flag_channeling"].notna().any() else False
    f_mix= bool(g["MG_flag_mixed"].dropna().iloc[-1]) if "MG_flag_mixed" in g and g["MG_flag_mixed"].notna().any() else False

    parts: List[str] = []
    if f_bc:  parts.append("–≤–æ–∑–º–æ–∂–Ω—ã –∑–∞–∫–æ–ª–æ–Ω–Ω—ã–µ –ø–µ—Ä–µ—Ç–æ–∫–∏ (—Ä–∞–Ω–Ω–∏–π –Ω–µ—Ñ—Ç–µ–æ—Ç–±–æ—Ä Y‚âà1)")
    if f_ch:  parts.append("–ø—Ä–∏–∑–Ω–∞–∫–∏ –∫–∞–Ω–∞–ª–∏—Ä–æ–≤–∞–Ω–∏—è (–∫—Ä—É—Ç–æ–π —Å–ø–∞–¥ Y –≤ –ø–µ—Ä–≤–æ–π —Ç—Ä–µ—Ç–∏)")
    if f_mix: parts.append("—Å–º–µ—à–∞–Ω–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã (–≤—ã—Å–æ–∫–∞—è –≤–æ–ª–Ω–∏—Å—Ç–æ—Å—Ç—å dY/dX)")
    if not parts: parts.append("—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ –±–ª–∏–∂–µ –∫ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–º—É –æ–±–≤–æ–¥–Ω–µ–Ω–∏—é")

    detail = f"MG –º–µ—Ç—Ä–∏–∫–∏: y_early‚âà{y_early:.2f}; –Ω–∞–∫–ª–æ–Ω‚âà{slope:.2f}; –≤–æ–ª–Ω–∏—Å—Ç–æ—Å—Ç—å‚âà{wav:.2f}"
    return {"mg_text": "; ".join(parts), "mg_detail": detail}

def diagnose_chan_group(g: pd.DataFrame) -> Dict[str, str]:
    slope  = g["chan_slope_logWOR_logt"].dropna().iloc[-1] if "chan_slope_logWOR_logt" in g and g["chan_slope_logWOR_logt"].notna().any() else np.nan
    mean_d = g["chan_mean_dWOR_dt"].dropna().iloc[-1] if "chan_mean_dWOR_dt" in g and g["chan_mean_dWOR_dt"].notna().any() else np.nan
    std_d  = g["chan_std_dWOR_dt"].dropna().iloc[-1] if "chan_std_dWOR_dt" in g and g["chan_std_dWOR_dt"].notna().any() else np.nan
    f_cone = bool(g["chan_flag_coning"].dropna().iloc[-1]) if "chan_flag_coning" in g and g["chan_flag_coning"].notna().any() else False
    f_near = bool(g["chan_flag_near_wellbore"].dropna().iloc[-1]) if "chan_flag_near_wellbore" in g and g["chan_flag_near_wellbore"].notna().any() else False
    f_multi= bool(g["chan_flag_multilayer_channeling"].dropna().iloc[-1]) if "chan_flag_multilayer_channeling" in g and g["chan_flag_multilayer_channeling"].notna().any() else False

    parts: List[str] = []
    if f_multi: parts.append("–º–Ω–æ–≥–æ—Å–ª–æ–π–Ω–æ–µ –∫–∞–Ω–∞–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (—Ä–æ—Å—Ç WOR –∏ –¥–∏—Å–ø–µ—Ä—Å–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π)")
    if f_near:  parts.append("–ø—Ä–∏—Å—Ç–≤–æ–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã/—Ä–∞–Ω–Ω–∏–π –∫–∞–Ω–∞–ª (–æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π –Ω–∞–∫–ª–æ–Ω)")
    if f_cone:  parts.append("–≤–æ–∑–º–æ–∂–µ–Ω –∫–æ–Ω–∏–Ω–≥ (–Ω–∞–∫–ª–æ–Ω > 0.5 –ø—Ä–∏ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π)")
    if not parts: parts.append("–Ω–µ—Ç –≤—ã—Ä–∞–∂–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Ä–æ–±–ª–µ–º–Ω–æ–≥–æ –ø—Ä–∏—Ç–æ–∫–∞ –≤–æ–¥—ã")

    detail = f"Chan –º–µ—Ç—Ä–∏–∫–∏: –Ω–∞–∫–ª–æ–Ω‚âà{slope:.2f}; —Å—Ä–µ–¥–Ω. dWOR/dt‚âà{mean_d:.2e}; std‚âà{std_d:.2e}"
    return {"chan_text": "; ".join(parts), "chan_detail": detail}

# =========================
# –≠–∫—Å–ø–æ—Ä—Ç ¬´–≤—Å—ë –≤ –æ–¥–∏–Ω Excel¬ª —Å –∫–∞—Ä—Ç–∏–Ω–∫–∞–º–∏
# =========================
def _render_plot_image(kind: str, g: pd.DataFrame, well: str) -> BytesIO:
    """–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å matplotlib-–≥—Ä–∞—Ñ–∏–∫ –≤ PNG (–≤ –ø–∞–º—è—Ç–∏)."""
    buf = BytesIO()
    if kind == "MG":
        fig, ax = plt.subplots(figsize=(6, 4))
        ax.scatter(g["MG_X"], g["MG_Y"], s=16, label="MG: Y(X)")
        ax.set_title(f"MG ‚Äî —Å–∫–≤–∞–∂–∏–Ω–∞ {well}")
        ax.set_xlabel("X = Qt_cum / Qt_cum(T)")
        ax.set_ylabel("Y = Qo_cum / Qt_cum")
        ax.grid(True, alpha=0.3)
        ax.legend(loc="best")
    else:  # Chan
        fig, ax = plt.subplots(figsize=(6, 4))
        m_wor = (g["t_pos"] > 0) & (g["WOR"] > 0)
        m_der = (g["t_pos"] > 0) & (g["dWOR_dt_pos"] > 0)
        ax.plot(g.loc[m_wor, "t_pos"], g.loc[m_wor, "WOR"], marker="o", linestyle="none", markersize=4, label="WOR")
        ax.plot(g.loc[m_der, "t_pos"], g.loc[m_der, "dWOR_dt_pos"], linestyle="--", label="|dWOR/dt|")
        ax.set_xscale("log"); ax.set_yscale("log")
        ax.set_xlabel("t_pos (–¥–Ω–∏)"); ax.set_ylabel("WOR, |dWOR/dt|")
        ax.grid(True, which="both", alpha=0.3); ax.legend(loc="best")
        ax.set_title(f"Chan ‚Äî —Å–∫–≤–∞–∂–∏–Ω–∞ {well} (log‚Äìlog)")
    fig.tight_layout()
    fig.savefig(buf, format="png", dpi=150, bbox_inches="tight")
    plt.close(fig)
    buf.seek(0)
    return buf

def export_all_results_single_file(
    mg_df: pd.DataFrame, chan_df: pd.DataFrame, diagnosis_df: pd.DataFrame
) -> BytesIO:
    """
    –ò—Ç–æ–≥–æ–≤—ã–π XLSX:
      - Summary: diagnosis_df
      - MG: –±–ª–æ–∫–∏ –ø–æ —Å–∫–≤–∞–∂–∏–Ω–∞–º (—Ç–∞–±–ª–∏—Ü–∞ + –≥—Ä–∞—Ñ–∏–∫ —Å–ø—Ä–∞–≤–∞)
      - Chan: –±–ª–æ–∫–∏ –ø–æ —Å–∫–≤–∞–∂–∏–Ω–∞–º (—Ç–∞–±–ª–∏—Ü–∞ + –≥—Ä–∞—Ñ–∏–∫ —Å–ø—Ä–∞–≤–∞)
    """
    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        # Summary
        if diagnosis_df is not None and not diagnosis_df.empty:
            diagnosis_df.to_excel(writer, sheet_name="Summary", index=False)
            writer.sheets["Summary"].set_column(0, diagnosis_df.shape[1] - 1, 18)
        else:
            ws = writer.book.add_worksheet("Summary")
            ws.write(0, 0, "–ù–µ—Ç —Å–≤–æ–¥–Ω—ã—Ö –¥–∏–∞–≥–Ω–æ–∑–æ–≤")

        # MG
        ws_mg = writer.book.add_worksheet("MG")
        writer.sheets["MG"] = ws_mg
        cur_row = 0
        if mg_df is not None and not mg_df.empty:
            for well, g in mg_df.groupby("well", sort=False):
                title = f"–°–∫–≤–∞–∂–∏–Ω–∞ {well} ‚Äî MG"
                g_reset = g.reset_index(drop=True)
                g_reset.to_excel(writer, sheet_name="MG", index=False, startrow=cur_row + 1, startcol=0)
                ws_mg.write(cur_row, 0, title)
                ws_mg.set_column(0, min(8, g_reset.shape[1] - 1), 14)
                if g_reset.shape[1] > 9:
                    ws_mg.set_column(9, g_reset.shape[1] - 1, 16)
                img = _render_plot_image("MG", g, well)
                ws_mg.insert_image(cur_row + 1, 9, f"MG_{well}.png", {"image_data": img})
                cur_row = cur_row + 1 + len(g_reset) + 4
        else:
            ws_mg.write(0, 0, "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö MG")

        # Chan
        ws_ch = writer.book.add_worksheet("Chan")
        writer.sheets["Chan"] = ws_ch
        cur_row = 0
        if chan_df is not None and not chan_df.empty:
            for well, g in chan_df.groupby("well", sort=False):
                title = f"–°–∫–≤–∞–∂–∏–Ω–∞ {well} ‚Äî Chan"
                g_reset = g.reset_index(drop=True)
                g_reset.to_excel(writer, sheet_name="Chan", index=False, startrow=cur_row + 1, startcol=0)
                ws_ch.write(cur_row, 0, title)
                ws_ch.set_column(0, min(8, g_reset.shape[1] - 1), 14)
                if g_reset.shape[1] > 9:
                    ws_ch.set_column(9, g_reset.shape[1] - 1, 16)
                img = _render_plot_image("Chan", g, well)
                ws_ch.insert_image(cur_row + 1, 9, f"Chan_{well}.png", {"image_data": img})
                cur_row = cur_row + 1 + len(g_reset) + 4
        else:
            ws_ch.write(0, 0, "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö Chan")

    output.seek(0)
    return output

# =========================
# –û—Å–Ω–æ–≤–Ω–æ–π UI/–ø–æ—Ç–æ–∫
# =========================
def main() -> None:
    # –ö–Ω–æ–ø–∫–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —à–∞–±–ª–æ–Ω–∞
    upload_examples()

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    uploaded_file = st.file_uploader(label="**–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞**", accept_multiple_files=False)
    if uploaded_file is None:
        st.info("–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è .csv, .txt, .xls, .xlsx")
        return

    if uploaded_file.name.lower().endswith((".txt", ".csv")):
        df_raw = pd.read_csv(uploaded_file)
    elif uploaded_file.name.lower().endswith((".xls", ".xlsx")):
        df_raw = pd.read_excel(uploaded_file)
    else:
        st.error("–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö. –ó–∞–≥—Ä—É–∑–∏—Ç–µ .csv, .txt, .xls, .xlsx")
        return

    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞
    df = data_preparation(df_raw)

    # MG
    mg_df = compute_mg_full(df)
    st.text(f"[OK] MG —Ä–∞—Å—Å—á–∏—Ç–∞–Ω: —Å—Ç—Ä–æ–∫ {len(mg_df)}; —Å–∫–≤–∞–∂–∏–Ω {mg_df['well'].nunique() if not mg_df.empty else 0}")

    # Chan
    chan_df = compute_chan_full(df)
    st.text(f"[OK] Chan —Ä–∞—Å—Å—á–∏—Ç–∞–Ω: —Å—Ç—Ä–æ–∫ {len(chan_df)}; —Å–∫–≤–∞–∂–∏–Ω {chan_df['well'].nunique() if not chan_df.empty else 0}")

    # –í—ã–≤–æ–¥ –ø–æ —Å–∫–≤–∞–∂–∏–Ω–∞–º + —Å–±–æ—Ä —Å–≤–æ–¥–∫–∏
    rows: List[Dict[str, str]] = []
    wells_mg = set(mg_df["well"].unique() if not mg_df.empty else [])
    wells_ch = set(chan_df["well"].unique() if not chan_df.empty else [])
    all_wells = sorted(list(wells_mg.union(wells_ch)))

    for w in all_wells:
        mg_g = mg_df[mg_df["well"] == w] if not mg_df.empty else pd.DataFrame()
        ch_g = chan_df[chan_df["well"] == w] if not chan_df.empty else pd.DataFrame()

        mg_diag = diagnose_mg_group(mg_g) if not mg_g.empty else {"mg_text": "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö MG", "mg_detail": ""}
        ch_diag = diagnose_chan_group(ch_g) if not ch_g.empty else {"chan_text": "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö Chan", "chan_detail": ""}

        st.markdown(f'<h2 style="color: darkred;">–°–∫–≤–∞–∂–∏–Ω–∞ {w}</h2>', unsafe_allow_html=True)
        st.text(f"  MG:   {mg_diag['mg_text']}")
        if mg_diag["mg_detail"]:
            st.text(f"        {mg_diag['mg_detail']}")
        st.text(f"  Chan: {ch_diag['chan_text']}")
        if ch_diag["chan_detail"]:
            st.text(f"        {ch_diag['chan_detail']}")

        rows.append({"well": w, **mg_diag, **ch_diag})

        # --- –ì—Ä–∞—Ñ–∏–∫ MG ---
        st.markdown(f"##### MG-–≥—Ä–∞—Ñ–∏–∫ (Y vs X) ‚Äî —Å–∫–≤–∞–∂–∏–Ω–∞ {w}")
        st.text("–ö—Ä–∏–≤–∞—è –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–æ–ª—é –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–π –Ω–µ—Ñ—Ç–∏ (Y) –æ—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–π –∂–∏–¥–∫–æ—Å—Ç–∏ –ø—Ä–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–∏ –¥–æ–ª–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–π –∂–∏–¥–∫–æ—Å—Ç–∏ (X).")
        if not mg_g.empty:
            fig_mg, ax_mg = plt.subplots(figsize=(7, 4))
            ax_mg.scatter(mg_g["MG_X"], mg_g["MG_Y"], label="MG: Y(X)", s=16)
            ax_mg.set_title(f"MG ‚Äî —Å–∫–≤–∞–∂–∏–Ω–∞ {w}")
            ax_mg.set_xlabel("X = Qt_cum / Qt_cum(T)")
            ax_mg.set_ylabel("Y = Qo_cum / Qt_cum")
            ax_mg.grid(True, alpha=0.3)
            ax_mg.legend(loc="best")
            st.pyplot(fig_mg, use_container_width=False)
        else:
            st.text(f"  [!] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö MG –¥–ª—è —Å–∫–≤–∞–∂–∏–Ω—ã {w}")

        # --- –ì—Ä–∞—Ñ–∏–∫ Chan: –æ–¥–Ω–∞ –æ—Å—å, –æ–±–µ —à–∫–∞–ª—ã log ---
        st.markdown(f"##### Chan-–≥—Ä–∞—Ñ–∏–∫ (WOR –∏ |dWOR/dt|) ‚Äî —Å–∫–≤–∞–∂–∏–Ω–∞ {w} (log‚Äìlog)")
        st.text("–û–±–µ –∫—Ä–∏–≤—ã–µ –Ω–∞ –æ–¥–Ω–æ–º –≥—Ä–∞—Ñ–∏–∫–µ; –æ—Å–∏ X –∏ Y ‚Äî –ª–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∏–µ. –î–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π –æ—Ç–æ–±—Ä–∞–∂–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è.")
        if not ch_g.empty:
            fig_chan, ax = plt.subplots(figsize=(7, 4))
            m_wor = (ch_g["t_pos"] > 0) & (ch_g["WOR"] > 0)
            m_der = (ch_g["t_pos"] > 0) & (ch_g["dWOR_dt_pos"] > 0)
            ax.plot(ch_g.loc[m_wor, "t_pos"], ch_g.loc[m_wor, "WOR"], marker="o", linestyle="none", label="WOR", markersize=4)
            ax.plot(ch_g.loc[m_der, "t_pos"], ch_g.loc[m_der, "dWOR_dt_pos"], linestyle="--", label="|dWOR/dt|")
            ax.set_xscale("log"); ax.set_yscale("log")
            ax.set_xlabel("t_pos (–¥–Ω–∏)"); ax.set_ylabel("WOR, |dWOR/dt|")
            ax.grid(True, which="both", alpha=0.3); ax.legend(loc="best")
            ax.set_title(f"Chan ‚Äî —Å–∫–≤–∞–∂–∏–Ω–∞ {w} (log‚Äìlog)")
            st.pyplot(fig_chan, use_container_width=False)
        else:
            st.text(f"  [!] –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö Chan –¥–ª—è —Å–∫–≤–∞–∂–∏–Ω—ã {w}")

    diagnosis_df = pd.DataFrame(rows).sort_values("well").reset_index(drop=True)
    if not diagnosis_df.empty:
        st.markdown(f'<h2 style="color: darkred;">–°–í–û–î–ù–ê–Ø –¢–ê–ë–õ–ò–¶–ê –î–ò–ê–ì–ù–û–ó–û–í</h2>', unsafe_allow_html=True)
        st.table(diagnosis_df)
    else:
        st.text("\n[!] –ù–µ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –¥–∏–∞–≥–Ω–æ–∑–∞ (–≤–æ–∑–º–æ–∂–Ω–æ, –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –º–∞–ª–æ –≤–∞–ª–∏–¥–Ω—ã—Ö —Ç–æ—á–µ–∫).")

    # –ï–î–ò–ù–´–ô EXCEL (Summary + MG + Chan) —Å –≥—Ä–∞—Ñ–∏–∫–∞–º–∏
    result_bytes = export_all_results_single_file(mg_df, chan_df, diagnosis_df)
    st.download_button(
        label="–°–∫–∞—á–∞—Ç—å –µ–¥–∏–Ω—ã–π —Ñ–∞–π–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (Summary + MG + Chan)",
        data=result_bytes,
        file_name="Autodiagnostics_results.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

# =========================
# –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞
# =========================
if __name__ == "__main__":
    main()
```

–µ—Å–ª–∏ –Ω—É–∂–Ω–æ, –¥–æ–±–∞–≤–ª—é –∞–≤—Ç–æ—Ñ–∏–ª—å—Ç—Ä—ã/—É—Å–ª–æ–≤–Ω–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ Excel –∏ —ç–∫—Å–ø–æ—Ä—Ç SVG-–≥—Ä–∞—Ñ–∏–∫–æ–≤.

