from __future__ import annotations

import os
import re
import unicodedata
from dataclasses import dataclass
from io import BytesIO
from typing import Dict, List, Optional, Set

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import streamlit as st
import openpyxl  # –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ —Ñ–æ–ª–±—ç–∫–µ —ç–∫—Å–ø–æ—Ä—Ç–∞
from openpyxl.utils.dataframe import dataframe_to_rows

# =========================
# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
# =========================
EPS = 1e-9
TEMPLATE_PATH = "data/templates/–°–æ—Å–Ω–æ–≤—Å–∫–æ–µ_clean.xlsx"

# –ï–¥–∏–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ç–±–æ—Ä–∞ —Å–∫–≤–∞–∂–∏–Ω/—Ç–æ—á–µ–∫
MIN_POINTS = 8                # –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –≤–∞–ª–∏–¥–Ω—ã—Ö —Ç–æ—á–µ–∫ –¥–ª—è –æ–±–µ–∏—Ö –º–µ—Ç–æ–¥–∏–∫
SHARED_WATERCUT_THR = 0.02    # –ø–æ—Ä–æ–≥ –Ω–∞—á–∞–ª—å–Ω–æ–π –æ–±–≤–æ–¥–Ω—ë–Ω–Ω–æ—Å—Ç–∏ fw

st.set_page_config(
    layout="wide",
    initial_sidebar_state="auto",
    page_title="–ê–≤—Ç–æ–¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å–∫–≤–∞–∂–∏–Ω",
    page_icon="üõ¢Ô∏è",
)

# === –û–ø–∏—Å–∞–Ω–∏–µ ===
DESCRIPTION_MD = """
### –ü–æ—Å–∫–≤–∞–∂–∏–Ω–Ω—ã–π –∞–≤—Ç–æ–¥–∏–∞–≥–Ω–æ–∑ –Ω–µ—Ñ—Ç—è–Ω—ã—Ö —Å–∫–≤–∞–∂–∏–Ω –ø–æ –º–µ—Ö–∞–Ω–∏–∑–º—É –æ–±–≤–æ–¥–Ω–µ–Ω–∏—è

**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:** —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –º–µ—Ö–∞–Ω–∏–∑–º–∞ –æ–±–≤–æ–¥–Ω–µ–Ω–∏—è –ø–æ –¥–≤—É–º –ø–æ–¥—Ö–æ–¥–∞–º ‚Äî **Chan** –∏ **–ú–µ—Ä–∫—É–ª–æ–≤–æ–π‚Äì–ì–∏–Ω–∑–±—É—Ä–≥–∞ (MG)** ‚Äî –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –≤—ã–≤–æ–¥—ã, –≥—Ä–∞—Ñ–∏–∫–∏ –∏ –µ–¥–∏–Ω—ã–π Excel —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏.

**–ö–∞–∫ —Ä–∞–±–æ—Ç–∞—Ç—å:**
1. –°–∫–∞—á–∞–π—Ç–µ —à–∞–±–ª–æ–Ω –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ –µ–≥–æ;
2. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª (XLSX/XLS);
3. –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –¥–∏–∞–≥–Ω–æ–∑—ã –∏ –≥—Ä–∞—Ñ–∏–∫–∏ –ø–æ –∫–∞–∂–¥–æ–π —Å–∫–≤–∞–∂–∏–Ω–µ;
4. –°–∫–∞—á–∞–π—Ç–µ –µ–¥–∏–Ω—ã–π Excel —Å –¥–∞–Ω–Ω—ã–º–∏ –∏ –≥—Ä–∞—Ñ–∏–∫–∞–º–∏.

**–í–∞–∂–Ω–æ –ø—Ä–æ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –¥–∞–Ω–Ω—ã—Ö:**
- –ú–µ—Ç–æ–¥–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç **—Ä–∞–∑–Ω—ã–µ —Ä–∞–±–æ—á–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏ ¬´–æ—á–∏—Å—Ç–∫—É¬ª —Ç–æ—á–µ–∫**:
  - **MG** —Å—Ç—Ä–æ–∏—Ç—Å—è –ø–æ –∫—É–º—É–ª—è—Ç–∏–≤–Ω—ã–º –æ–±—ä—ë–º–∞–º –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫—Ä–∏–≤—É—é `Y = Qo_cum/Qt_cum` –æ—Ç `X = Qt_cum/Qt_cum(T)`. –ù–∞ —Å—Ç–∞—Ä—Ç–µ **–æ—Ç—Å–µ–∫–∞—é—Ç—Å—è** –ø–µ—Ä–∏–æ–¥—ã –¥–æ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –ø–æ—Ä–æ–≥–∞ –æ–±–≤–æ–¥–Ω—ë–Ω–Ω–æ—Å—Ç–∏ `fw = qw_period/qL_period > {thr:.2f}`; —Ç—Ä–µ–±—É—é—Ç—Å—è ‚â•{minp} –≤–∞–ª–∏–¥–Ω—ã—Ö —Ç–æ—á–µ–∫ **–ø–æ—Å–ª–µ** –ø–æ—Ä–æ–≥–∞.
  - **Chan** —Ä–∞–±–æ—Ç–∞–µ—Ç —Å `WOR = qw/qo` –≤–æ –≤—Ä–µ–º–µ–Ω–∏ (–ª–æ–≥‚Äì–ª–æ–≥ —à–∫–∞–ª—ã), –ø–æ—ç—Ç–æ–º—É **–æ—Ç–±—Ä–∞—Å—ã–≤–∞—é—Ç—Å—è** —Ç–æ—á–∫–∏ —Å –Ω–µ–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–º–∏ `qo`, `WOR` –∏ –Ω—É–ª–µ–≤—ã–º –≤—Ä–µ–º–µ–Ω–µ–º; –¥–∞–ª–µ–µ –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è –Ω–∞–∫–ª–æ–Ω –≤ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö `log(t)`‚Äì`log(WOR)` –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è `dWOR/dt`.
- –ß—Ç–æ–±—ã **–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∫–≤–∞–∂–∏–Ω —Å–æ–≤–ø–∞–¥–∞–ª–æ** –≤ —Å–≤–æ–¥–∫–µ MG –∏ Chan, –≤—ã–±–∏—Ä–∞–µ–º **–µ–¥–∏–Ω—ã–π —Å–ø–∏—Å–æ–∫ ¬´–¥–æ–ø—É—â–µ–Ω–Ω—ã—Ö¬ª —Å–∫–≤–∞–∂–∏–Ω** –ø–æ –ø—Ä–æ—Å—Ç–æ–º—É –ø—Ä–∞–≤–∏–ª—É (–∫–∞–∫ –¥–ª—è MG): —É —Å–∫–≤–∞–∂–∏–Ω—ã –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å ‚â•{minp} –≤–∞–ª–∏–¥–Ω—ã—Ö —Ç–æ—á–µ–∫, –≥–¥–µ `fw > {thr:.2f}` –∏ –µ—Å—Ç—å –ø—Ä–æ–¥–æ–ª–∂–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–µ—Ä–∏–æ–¥–∞. Chan –∑–∞—Ç–µ–º –≤–Ω—É—Ç—Ä–∏ —Å–∫–≤–∞–∂–∏–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ —á–∏—Å—Ç–∏—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏, –Ω–æ **—Å–ø–∏—Å–æ–∫ —Å–∫–≤–∞–∂–∏–Ω –æ—Å—Ç–∞—ë—Ç—Å—è –æ–¥–Ω–∏–º –∏ —Ç–µ–º –∂–µ**.
""".format(thr=SHARED_WATERCUT_THR, minp=MIN_POINTS)
st.markdown(DESCRIPTION_MD)


# =========================
# –£—Ç–∏–ª–∏—Ç—ã
# =========================
def excel_letter_to_index(letter: str) -> int:
    letter = letter.strip().upper()
    acc = 0
    for ch in letter:
        if not ("A" <= ch <= "Z"):
            raise ValueError(f"–ù–µ–≤–µ—Ä–Ω–∞—è –±—É–∫–≤–∞ —Å—Ç–æ–ª–±—Ü–∞ Excel: {letter}")
        acc = acc * 26 + (ord(ch) - ord("A") + 1)
    return acc - 1

def col_by_letter(df: pd.DataFrame, letter: str) -> Optional[str]:
    idx = excel_letter_to_index(letter)
    return df.columns[idx] if 0 <= idx < len(df.columns) else None

def series_by_letter(df: pd.DataFrame, letter: str) -> Optional[pd.Series]:
    col = col_by_letter(df, letter)
    return df.get(col)

def normalize_header(s: str) -> str:
    if not isinstance(s, str):
        return str(s)
    s = unicodedata.normalize("NFKC", s).replace("\u00A0", " ").replace("\xa0", " ")
    return re.sub(r"\s+", " ", s.strip())

def to_num_or_nan(ser: Optional[pd.Series], df: pd.DataFrame, fill: Optional[float] = None) -> pd.Series:
    if isinstance(ser, pd.Series):
        out = pd.to_numeric(ser, errors="coerce")
    else:
        out = pd.Series(np.nan, index=df.index, dtype=float)
    if fill is not None:
        out = out.fillna(fill)
    return out

def read_template_df() -> pd.DataFrame:
    try:
        if os.path.exists(TEMPLATE_PATH):
            return pd.read_excel(TEMPLATE_PATH)
    except Exception:
        pass
    return pd.DataFrame()

def upload_examples() -> None:
    tpl = read_template_df()
    st.write("**–°–∫–∞—á–∞—Ç—å —à–∞–±–ª–æ–Ω –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö:**")
    out_excel = BytesIO()
    tpl.to_excel(out_excel, index=False, engine="openpyxl")
    out_excel.seek(0)
    st.download_button(
        "–°–∫–∞—á–∞—Ç—å —à–∞–±–ª–æ–Ω (XLSX)",
        data=out_excel,
        file_name="template.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
    )

def safe_gradient_series(y: pd.Series, x: pd.Series) -> pd.Series:
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞—Å—á—ë—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π: –µ—Å–ª–∏ —Ç–æ—á–µ–∫ < 2 ‚Äî –≤–µ—Ä–Ω—ë–º NaN."""
    y = pd.to_numeric(y, errors="coerce")
    x = pd.to_numeric(x, errors="coerce")
    if len(y) < 2 or len(x) < 2 or y.dropna().shape[0] < 2 or x.dropna().shape[0] < 2:
        return pd.Series(np.nan, index=y.index, dtype=float)
    try:
        return pd.Series(np.gradient(y, x), index=y.index)
    except Exception:
        return pd.Series(np.nan, index=y.index, dtype=float)

def autosize_worksheet_columns(ws, df: pd.DataFrame, startcol: int = 0):
    """–ü—Ä–æ—Å—Ç–µ–π—à–∏–π –∞–≤—Ç–æ–ø–æ–¥–±–æ—Ä —à–∏—Ä–∏–Ω—ã –¥–ª—è xlsxwriter."""
    for i, col in enumerate(df.columns):
        width = max(len(str(col)), int(df[col].astype(str).str.len().max() or 0)) + 2
        try:
            ws.set_column(startcol + i, startcol + i, min(width, 60))
        except Exception:
            pass


# =========================
# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥ MG/Chan
# =========================
def enforce_monotonic_per_well(dfin: pd.DataFrame) -> pd.DataFrame:
    if dfin.empty:
        return dfin
    return dfin.groupby("well", sort=False, group_keys=False).apply(
        lambda g: g.assign(t_num=g["t_num"].cummax().add(np.arange(len(g)) * EPS))
    )

def data_preparation(init_data: pd.DataFrame) -> pd.DataFrame:
    df = init_data.copy()
    df.columns = [normalize_header(c) for c in df.columns]

    sH  = series_by_letter(df, "H")
    sI  = series_by_letter(df, "I")
    sX  = series_by_letter(df, "X")
    sAB = series_by_letter(df, "AB")
    sBT = series_by_letter(df, "BT")
    sBS = series_by_letter(df, "BS")
    sBR = series_by_letter(df, "BR")
    sAJ = series_by_letter(df, "AJ")

    # Well_calc -> well
    well_series = pd.Series("", index=df.index, dtype=str)
    if sH is not None:
        well_series += sH.astype(str).str.strip().fillna("")
    if sI is not None:
        well_series = well_series.str.strip() + " " + sI.astype(str).str.strip().fillna("")
    df["well"] = well_series.str.strip()

    # –ü—Ä–æ–∏–∑–≤–æ–¥–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
    X_vals  = to_num_or_nan(sX,  df)
    AB_vals = to_num_or_nan(sAB, df)
    df["–î–æ–±—ã—á–∞ –Ω–µ—Ñ—Ç–∏ –º3/–º–µ—Å"] = X_vals * (100.0 - AB_vals) / 100.0
    df["–î–æ–±—ã—á–∞ –≤–æ–¥—ã –º3/–º–µ—Å"]  = X_vals * AB_vals / 100.0

    BT_vals = to_num_or_nan(sBT, df)
    BS_vals = to_num_or_nan(sBS, df)
    with np.errstate(divide="ignore", invalid="ignore"):
        df["–í–ù–§"] = BT_vals / BS_vals

    # –ù–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã
    if sBR is not None and sAJ is not None:
        br_series = sBR.astype(str).fillna("")
        aj_series = pd.to_numeric(sAJ, errors="coerce").fillna(0.0)
        new_period_marker = (df['well'] != df['well'].shift()) | (br_series != br_series.shift())
        period_group = new_period_marker.cumsum()
        df["–ù–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã"] = aj_series.groupby([df['well'], period_group]).cumsum()
    else:
        df["–ù–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã"] = 0.0

    # –í–ù–§' (–±–µ–∑–æ–ø–∞—Å–Ω–æ)
    df = df.sort_values(["well", "–ù–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã"]).reset_index(drop=True)
    df["–í–ù–§'"] = (
        df.groupby("well", sort=False)
          .apply(lambda g: safe_gradient_series(g["–í–ù–§"], g["–ù–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã"]))
          .reset_index(level=0, drop=True)
    )

    # –û–±—ä—ë–º—ã –ø–µ—Ä–∏–æ–¥–∞ –∏ —Å—É—Ç–æ—á–Ω—ã–µ –¥–µ–±–∏—Ç—ã
    df["qo_period"] = pd.to_numeric(df["–î–æ–±—ã—á–∞ –Ω–µ—Ñ—Ç–∏ –º3/–º–µ—Å"], errors="coerce").fillna(0.0)
    df["qw_period"] = pd.to_numeric(df["–î–æ–±—ã—á–∞ –≤–æ–¥—ã –º3/–º–µ—Å"],  errors="coerce").fillna(0.0)
    df["qL_period"] = df["qo_period"] + df["qw_period"]

    df["prod_days"] = to_num_or_nan(sAJ, df, fill=0.0)
    with np.errstate(divide="ignore", invalid="ignore"):
        df["qo"] = df["qo_period"] / df["prod_days"]
        df["qw"] = df["qw_period"] / df["prod_days"]
        df["qL"] = df["qL_period"] / df["prod_days"]

    df["t_num"] = df["–ù–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã"]
    df = df.dropna(subset=["well", "t_num"]).sort_values(["well", "t_num"]).reset_index(drop=True)
    df = enforce_monotonic_per_well(df)
    return df


# =========================
# –ï–¥–∏–Ω—ã–π –æ—Ç–±–æ—Ä —Å–∫–≤–∞–∂–∏–Ω
# =========================
def select_eligible_wells(df: pd.DataFrame,
                          min_points: int = MIN_POINTS,
                          watercut_thr: float = SHARED_WATERCUT_THR) -> Set[str]:
    """–°–ø–∏—Å–æ–∫ —Å–∫–≤–∞–∂–∏–Ω, —É –∫–æ—Ç–æ—Ä—ã—Ö ‚â•min_points –≤–∞–ª–∏–¥–Ω—ã—Ö —Ç–æ—á–µ–∫ –ü–û–°–õ–ï –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –ø–æ—Ä–æ–≥–∞ fw > watercut_thr."""
    d = df.copy()
    with np.errstate(divide="ignore", invalid="ignore"):
        d["fw"] = d["qw_period"] / d["qL_period"]
    d = d.replace([np.inf, -np.inf], np.nan)

    eligible: Set[str] = set()
    for w, g in d.groupby("well", sort=False):
        g = g.sort_values("t_num")
        mask = (g["qL_period"] > 0) & (g["fw"] > watercut_thr) & (g["prod_days"] > 0)
        if mask.sum() >= min_points:
            eligible.add(w)
    return eligible


# =========================
# MG
# =========================
@dataclass
class MGFlags:
    y_early_mean: Optional[float] = None
    slope_first_third: Optional[float] = None
    waviness_std: Optional[float] = None
    possible_behind_casing: bool = False
    possible_channeling: bool = False
    possible_mixed_causes: bool = False

def compute_mg_full(df_in: pd.DataFrame,
                    eligible_wells: Optional[Set[str]] = None,
                    watercut_thr: float = SHARED_WATERCUT_THR,
                    min_points: int = MIN_POINTS) -> pd.DataFrame:
    d = df_in.copy()
    if eligible_wells is not None:
        d = d[d["well"].isin(eligible_wells)]

    with np.errstate(divide="ignore", invalid="ignore"):
        d["fw"] = d["qw_period"] / d["qL_period"]
        d["fw"] = d["fw"].replace([np.inf, -np.inf], np.nan)

    frames = []
    for w, g in d.groupby("well", sort=False):
        g = g.sort_values("t_num").copy()
        idx = g.index[g["fw"] > watercut_thr]
        if len(idx) == 0 or len(g) < min_points:
            continue
        g2 = g.loc[idx[0]:].copy()

        g2["Qo_cum"] = g2["qo_period"].cumsum()
        g2["Qw_cum"] = g2["qw_period"].cumsum()
        g2["Qt_cum"] = g2["Qo_cum"] + g2["Qw_cum"]

        Qt_T = float(g2["Qt_cum"].iloc[-1])
        if Qt_T <= 0 or len(g2) < min_points:
            continue
        
        X = g2["Qt_cum"] / Qt_T
        X_mono = X.cummax().add(np.arange(len(X)) * EPS)
        g2["MG_X"] = X_mono
        with np.errstate(invalid="ignore", divide="ignore"):
            g2["MG_Y"] = g2["Qo_cum"] / g2["Qt_cum"]

        flags = MGFlags()
        early_mask = g2["MG_X"] <= 0.2
        if early_mask.sum() >= 3:
            flags.y_early_mean = float(np.nanmean(g2.loc[early_mask, "MG_Y"]))
            flags.possible_behind_casing = (flags.y_early_mean is not None) and (flags.y_early_mean >= 0.99)

        first_third = g2[g2["MG_X"] <= 0.33]
        if len(first_third) >= 3:
            try:
                k, _ = np.polyfit(first_third["MG_X"], first_third["MG_Y"], 1)
                flags.slope_first_third = float(k)
                flags.possible_channeling = (k < -0.8)
            except np.linalg.LinAlgError:
                pass
        
        if len(g2) >= 5:
            with np.errstate(invalid="ignore"):
                dy = np.gradient(g2["MG_Y"], g2["MG_X"])
            flags.waviness_std = float(np.nanstd(dy))
            flags.possible_mixed_causes = flags.waviness_std > 1.0

        for key, val in vars(flags).items():
            g2[f"MG_diag_{key}"] = val
        frames.append(g2)

    return pd.concat(frames, axis=0).reset_index(drop=True) if frames else pd.DataFrame()


# =========================
# Chan
# =========================
@dataclass
class ChanFlags:
    slope_logWOR_logt: Optional[float] = None
    mean_derivative: Optional[float] = None
    std_derivative: Optional[float] = None
    possible_coning: bool = False
    possible_near_wellbore: bool = False
    possible_multilayer_channeling: bool = False

def compute_chan_full(df_in: pd.DataFrame,
                      eligible_wells: Optional[Set[str]] = None,
                      min_points: int = MIN_POINTS) -> pd.DataFrame:
    frames = []
    d = df_in.copy()
    if eligible_wells is not None:
        d = d[d["well"].isin(eligible_wells)]

    for w, g in d.groupby("well", sort=False):
        g = g.sort_values("t_num").copy()
        with np.errstate(divide="ignore", invalid="ignore"):
            g["WOR"] = g["qw"] / g["qo"]
        g = g.replace([np.inf, -np.inf], np.nan)
        g = g[(g["qo"] > 0) & (g["WOR"] > 0)].dropna(subset=["WOR"])
        if len(g) < min_points:
            continue

        with np.errstate(invalid="ignore"):
            g["t_pos"] = g["t_num"] - g["t_num"].min() + EPS
            g["dWOR_dt"] = np.gradient(g["WOR"], g["t_pos"])
        
        mask = (g["WOR"] > 0) & (g["t_pos"] > 0)
        a = np.nan
        if mask.sum() >= 3:
            x = np.log(g.loc[mask, "t_pos"])
            y = np.log(g.loc[mask, "WOR"])
            try:
                a, _ = np.polyfit(x, y, 1)
            except np.linalg.LinAlgError:
                pass
        
        flags = ChanFlags()
        flags.slope_logWOR_logt = float(a)
        flags.mean_derivative = float(np.nanmean(g["dWOR_dt"]))
        flags.std_derivative = float(np.nanstd(g["dWOR_dt"]))
        
        if not np.isnan(a):
            flags.possible_coning = a > 0.5 and flags.mean_derivative > 0
            flags.possible_near_wellbore = a > 1.0 and flags.mean_derivative > 0
            flags.possible_multilayer_channeling = a > 0 and flags.std_derivative > 0.1

        for key, val in vars(flags).items():
            g[f"chan_diag_{key}"] = val
        g["dWOR_dt_pos"] = np.where(g["dWOR_dt"] > 0, g["dWOR_dt"], np.nan)
        frames.append(g)

    return pd.concat(frames, axis=0).reset_index(drop=True) if frames else pd.DataFrame()


# =========================
# –¢–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∏–∞–≥–Ω–æ–∑—ã
# =========================
def diagnose_mg_group(g: pd.DataFrame) -> Dict[str, str]:
    if g.empty: return {"mg_text": "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö MG", "mg_detail": ""}
    last_row = g.iloc[-1]
    y_early = last_row.get("MG_diag_y_early_mean", np.nan)
    slope = last_row.get("MG_diag_slope_first_third", np.nan)
    wav = last_row.get("MG_diag_waviness_std", np.nan)

    parts: List[str] = []
    if last_row.get("MG_diag_possible_behind_casing"): parts.append("–≤–æ–∑–º–æ–∂–Ω—ã –∑–∞–∫–æ–ª–æ–Ω–Ω—ã–µ –ø–µ—Ä–µ—Ç–æ–∫–∏ (—Ä–∞–Ω–Ω–∏–π –Ω–µ—Ñ—Ç–µ–æ—Ç–±–æ—Ä Y‚âà1)")
    if last_row.get("MG_diag_possible_channeling"):    parts.append("–ø—Ä–∏–∑–Ω–∞–∫–∏ –∫–∞–Ω–∞–ª–∏—Ä–æ–≤–∞–Ω–∏—è (–∫—Ä—É—Ç–æ–π —Å–ø–∞–¥ Y –≤ –ø–µ—Ä–≤–æ–π —Ç—Ä–µ—Ç–∏)")
    if last_row.get("MG_diag_possible_mixed_causes"):  parts.append("—Å–º–µ—à–∞–Ω–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã (–≤—ã—Å–æ–∫–∞—è –≤–æ–ª–Ω–∏—Å—Ç–æ—Å—Ç—å dY/dX)")
    if not parts: parts.append("–±–ª–∏–∂–µ –∫ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ–º—É –æ–±–≤–æ–¥–Ω–µ–Ω–∏—é")
    
    detail = f"MG –º–µ—Ç—Ä–∏–∫–∏: y_early‚âà{y_early:.2f}; –Ω–∞–∫–ª–æ–Ω‚âà{slope:.2f}; –≤–æ–ª–Ω–∏—Å—Ç–æ—Å—Ç—å‚âà{wav:.2f}"
    return {"mg_text": "; ".join(parts), "mg_detail": detail}

def diagnose_chan_group(g: pd.DataFrame) -> Dict[str, str]:
    if g.empty: return {"chan_text": "–Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö Chan", "chan_detail": ""}
    last_row = g.iloc[-1]
    slope = last_row.get("chan_diag_slope_logWOR_logt", np.nan)
    mean_d = last_row.get("chan_diag_mean_derivative", np.nan)
    std_d = last_row.get("chan_diag_std_derivative", np.nan)

    parts: List[str] = []
    if last_row.get("chan_diag_possible_multilayer_channeling"): parts.append("–º–Ω–æ–≥–æ—Å–ª–æ–π–Ω–æ–µ –∫–∞–Ω–∞–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (—Ä–æ—Å—Ç WOR –∏ –¥–∏—Å–ø–µ—Ä—Å–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π)")
    if last_row.get("chan_diag_possible_near_wellbore"):         parts.append("–ø—Ä–∏—Å—Ç–≤–æ–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã/—Ä–∞–Ω–Ω–∏–π –∫–∞–Ω–∞–ª (–æ—á–µ–Ω—å –≤—ã—Å–æ–∫–∏–π –Ω–∞–∫–ª–æ–Ω)")
    if last_row.get("chan_diag_possible_coning"):                parts.append("–≤–æ–∑–º–æ–∂–µ–Ω –∫–æ–Ω–∏–Ω–≥ (–Ω–∞–∫–ª–æ–Ω > 0.5 –ø—Ä–∏ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–æ–π)")
    if not parts: parts.append("–Ω–µ—Ç –≤—ã—Ä–∞–∂–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ø—Ä–æ–±–ª–µ–º–Ω–æ–≥–æ –ø—Ä–∏—Ç–æ–∫–∞ –≤–æ–¥—ã")
    
    detail = f"Chan –º–µ—Ç—Ä–∏–∫–∏: –Ω–∞–∫–ª–æ–Ω‚âà{slope:.2f}; —Å—Ä–µ–¥–Ω. dWOR/dt‚âà{mean_d:.2e}; std‚âà{std_d:.2e}"
    return {"chan_text": "; ".join(parts), "chan_detail": detail}


# =========================
# –≠–∫—Å–ø–æ—Ä—Ç XLSX —Å —Ñ–æ–ª–±—ç–∫–æ–º
# =========================
def export_all_results_single_file(mg_df: pd.DataFrame,
                                   chan_df: pd.DataFrame,
                                   diagnosis_df: pd.DataFrame) -> BytesIO:
    """
    –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º xlsxwriter (—Å –Ω–∞—Ç–∏–≤–Ω—ã–º–∏ –≥—Ä–∞—Ñ–∏–∫–∞–º–∏).
    –ï—Å–ª–∏ –º–æ–¥—É–ª—å –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç ‚Äî —Ñ–æ–ª–±—ç–∫ –Ω–∞ openpyxl (–±–µ–∑ –≥—Ä–∞—Ñ–∏–∫–æ–≤).
    """
    output = BytesIO()

    # --- –ü–æ–ø—ã—Ç–∫–∞ 1: xlsxwriter
    try:
        with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
            wb = writer.book

            # Summary
            diagnosis_df.to_excel(writer, sheet_name="Summary", index=False)
            autosize_worksheet_columns(writer.sheets["Summary"], diagnosis_df)

            # MG
            ws_mg = wb.add_worksheet("MG"); writer.sheets["MG"] = ws_mg
            row = 0
            if not mg_df.empty:
                for well, g in mg_df.groupby("well", sort=False):
                    ws_mg.write(row, 0, f"–°–∫–≤–∞–∂–∏–Ω–∞ {well} ‚Äî MG")
                    row += 1
                    g0 = g.reset_index(drop=True)
                    g0.to_excel(writer, sheet_name="MG", index=False, startrow=row)
                    autosize_worksheet_columns(ws_mg, g0)
                    # –≥—Ä–∞—Ñ–∏–∫
                    chart = wb.add_chart({'type': 'scatter'})
                    n = len(g0)
                    cx = g0.columns.get_loc("MG_X") + 1
                    cy = g0.columns.get_loc("MG_Y") + 1
                    chart.add_series({
                        'name': f'–°–∫–≤–∞–∂–∏–Ω–∞ {well}',
                        'categories': ['MG', row + 1, cx, row + n, cx],
                        'values':     ['MG', row + 1, cy, row + n, cy],
                        'marker': {'type': 'circle', 'size': 5},
                    })
                    chart.set_title({'name': f'MG ‚Äî –°–∫–≤–∞–∂–∏–Ω–∞ {well}'})
                    chart.set_x_axis({'name': 'X = Qt_cum / Qt_cum(T)'})
                    chart.set_y_axis({'name': 'Y = Qo_cum / Qt_cum'})
                    chart.set_legend({'position': 'none'})
                    ws_mg.insert_chart(row, g0.shape[1] + 1, chart)
                    row += n + 5
            else:
                ws_mg.write(0, 0, "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö MG")

            # Chan
            ws_ch = wb.add_worksheet("Chan"); writer.sheets["Chan"] = ws_ch
            row = 0
            if not chan_df.empty:
                for well, g in chan_df.groupby("well", sort=False):
                    ws_ch.write(row, 0, f"–°–∫–≤–∞–∂–∏–Ω–∞ {well} ‚Äî Chan")
                    row += 1
                    g0 = g.reset_index(drop=True)
                    g0.to_excel(writer, sheet_name="Chan", index=False, startrow=row)
                    autosize_worksheet_columns(ws_ch, g0)
                    chart = wb.add_chart({'type': 'scatter', 'subtype': 'straight_with_markers'})
                    n = len(g0)
                    ct = g0.columns.get_loc("t_pos") + 1
                    cw = g0.columns.get_loc("WOR") + 1
                    cd = g0.columns.get_loc("dWOR_dt_pos") + 1
                    chart.add_series({
                        'name': 'WOR',
                        'categories': ['Chan', row + 1, ct, row + n, ct],
                        'values':     ['Chan', row + 1, cw, row + n, cw],
                        'marker': {'type': 'circle', 'size': 5},
                        'line': {'none': True},
                    })
                    chart.add_series({
                        'name': '|dWOR/dt|',
                        'categories': ['Chan', row + 1, ct, row + n, ct],
                        'values':     ['Chan', row + 1, cd, row + n, cd],
                        'marker': {'type': 'none'},
                        'line': {'dash_type': 'dash'},
                    })
                    chart.set_title({'name': f'Chan ‚Äî –°–∫–≤–∞–∂–∏–Ω–∞ {well}'})
                    chart.set_x_axis({'name': 't_pos (–¥–Ω–∏)', 'log_base': 10})
                    chart.set_y_axis({'name': 'WOR, |dWOR/dt|', 'log_base': 10})
                    ws_ch.insert_chart(row, g0.shape[1] + 1, chart)
                    row += n + 5
            else:
                ws_ch.write(0, 0, "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö Chan")

    # --- –ü–æ–ø—ã—Ç–∫–∞ 2: openpyxl (–±–µ–∑ –≥—Ä–∞—Ñ–∏–∫–æ–≤)
    except ModuleNotFoundError:
        output = BytesIO()
        with pd.ExcelWriter(output, engine="openpyxl") as writer:
            diagnosis_df.to_excel(writer, sheet_name="Summary", index=False)
            if not mg_df.empty:
                mg_df.to_excel(writer, sheet_name="MG", index=False)
            if not chan_df.empty:
                chan_df.to_excel(writer, sheet_name="Chan", index=False)

    output.seek(0)
    return output


# =========================
# –û—Å–Ω–æ–≤–Ω–æ–π UI/–ø–æ—Ç–æ–∫
# =========================
def main() -> None:
    upload_examples()
    uploaded_file = st.file_uploader(label="**–ó–∞–≥—Ä—É–∑–∏—Ç–µ XLSX/XLS —Ñ–∞–π–ª –¥–ª—è —Ä–∞—Å—á—ë—Ç–∞**", type=["xlsx", "xls"])
    if uploaded_file is None:
        st.info("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª, —Å–æ–∑–¥–∞–Ω–Ω—ã–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —à–∞–±–ª–æ–Ω–∞.")
        return

    try:
        with st.spinner("–ß—Ç–µ–Ω–∏–µ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö..."):
            df_raw = pd.read_excel(uploaded_file)
            df = data_preparation(df_raw)

        # –µ–¥–∏–Ω—ã–π —Å–ø–∏—Å–æ–∫ —Å–∫–≤–∞–∂–∏–Ω
        eligible = select_eligible_wells(df, min_points=MIN_POINTS, watercut_thr=SHARED_WATERCUT_THR)

        with st.spinner("–†–∞—Å—á—ë—Ç –ø–æ –º–µ—Ç–æ–¥–∏–∫–µ –ú–µ—Ä–∫—É–ª–æ–≤–æ–π‚Äì–ì–∏–Ω–∑–±—É—Ä–≥–∞..."):
            mg_df = compute_mg_full(df, eligible_wells=eligible)
        st.success(f"‚úîÔ∏è MG: —Ä–∞—Å—á—ë—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω –¥–ª—è {len(eligible)} —Å–∫–≤–∞–∂–∏–Ω.")

        with st.spinner("–†–∞—Å—á—ë—Ç –ø–æ –º–µ—Ç–æ–¥–∏–∫–µ Chan..."):
            chan_df = compute_chan_full(df, eligible_wells=eligible)
        st.success(f"‚úîÔ∏è Chan: —Ä–∞—Å—á—ë—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω –¥–ª—è {len(eligible)} —Å–∫–≤–∞–∂–∏–Ω.")

        rows: List[Dict[str, str]] = []
        all_wells = sorted(list(eligible))
        if not all_wells:
            st.warning("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–∫–≤–∞–∂–∏–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª.")
            return

        for w in all_wells:
            mg_g = mg_df[mg_df["well"] == w] if not mg_df.empty else pd.DataFrame()
            ch_g = chan_df[chan_df["well"] == w] if not chan_df.empty else pd.DataFrame()

            mg_diag = diagnose_mg_group(mg_g)
            ch_diag = diagnose_chan_group(ch_g)
            rows.append({"well": w, **mg_diag, **ch_diag})

            with st.expander(f"–î–∏–∞–≥–Ω–æ–∑ –∏ –≥—Ä–∞—Ñ–∏–∫–∏ –¥–ª—è —Å–∫–≤–∞–∂–∏–Ω—ã: {w}"):
                st.markdown(f"#### üìú –î–∏–∞–≥–Ω–æ–∑: {w}")
                col1, col2 = st.columns(2)
                col1.metric("–î–∏–∞–≥–Ω–æ–∑ MG", mg_diag['mg_text'], help=mg_diag['mg_detail'])
                col2.metric("–î–∏–∞–≥–Ω–æ–∑ Chan", ch_diag['chan_text'], help=ch_diag['chan_detail'])

                st.markdown(f"#### üìà –ì—Ä–∞—Ñ–∏–∫–∏: {w}")
                plot_col1, plot_col2 = st.columns(2)

                with plot_col1:
                    if not mg_g.empty:
                        fig_mg, ax_mg = plt.subplots()
                        ax_mg.scatter(mg_g["MG_X"], mg_g["MG_Y"], s=16)
                        ax_mg.set_title(f"MG ‚Äî —Å–∫–≤–∞–∂–∏–Ω–∞ {w}")
                        ax_mg.set_xlabel("X = Qt_cum / Qt_cum(T)")
                        ax_mg.set_ylabel("Y = Qo_cum / Qt_cum")
                        ax_mg.grid(True, alpha=0.3)
                        st.pyplot(fig_mg)
                    else:
                        st.info(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö MG –¥–ª—è {w}")

                with plot_col2:
                    if not ch_g.empty:
                        fig_chan, ax = plt.subplots()
                        ax.plot(ch_g["t_pos"], ch_g["WOR"], "o", markersize=4, label="WOR")
                        ax.plot(ch_g["t_pos"], ch_g["dWOR_dt_pos"], "--", label="|dWOR/dt|")
                        ax.set_xscale("log"); ax.set_yscale("log")
                        ax.set_xlabel("t_pos (–¥–Ω–∏)"); ax.set_ylabel("WOR, |dWOR/dt|")
                        ax.grid(True, which="both", alpha=0.3); ax.legend()
                        ax.set_title(f"Chan ‚Äî —Å–∫–≤–∞–∂–∏–Ω–∞ {w} (log‚Äìlog)")
                        st.pyplot(fig_chan)
                    else:
                        st.info(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö Chan –¥–ª—è {w}")

        diagnosis_df = pd.DataFrame(rows).sort_values("well").reset_index(drop=True)
        if not diagnosis_df.empty:
            st.markdown("---")
            st.subheader("–°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –¥–∏–∞–≥–Ω–æ–∑–æ–≤")
            st.dataframe(diagnosis_df)

        st.markdown("---")
        st.subheader("üì• –°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã")
        result_bytes = export_all_results_single_file(mg_df, chan_df, diagnosis_df)
        st.download_button(
            label="–°–∫–∞—á–∞—Ç—å –µ–¥–∏–Ω—ã–π Excel-—Ñ–∞–π–ª (—Ç–∞–±–ª–∏—Ü—ã + –≥—Ä–∞—Ñ–∏–∫–∏*)",
            data=result_bytes,
            file_name="Autodiagnostics_results.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            help="*–ì—Ä–∞—Ñ–∏–∫–∏ –≤—Å—Ç—Ä–∞–∏–≤–∞—é—Ç—Å—è, –µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –º–æ–¥—É–ª—å xlsxwriter; –∏–Ω–∞—á–µ —Å–æ–∑–¥–∞—ë—Ç—Å—è —Ñ–∞–π–ª –±–µ–∑ –≥—Ä–∞—Ñ–∏–∫–æ–≤.",
        )

    except Exception as e:
        st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {e}")
        st.warning("–£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ñ–∞–π–ª–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —à–∞–±–ª–æ–Ω—É.")

# =========================
# –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞
# =========================
if __name__ == "__main__":
    main()
